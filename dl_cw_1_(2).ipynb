{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waimianzaixiayu/BasicWebApp/blob/master/dl_cw_1_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVYtNKvZuW4y"
      },
      "source": [
        "# Coursework1: Convolutional Neural Networks \n",
        "### Autograding\n",
        "Part 1 of this coursework is autograded. This notebook comes with embedded tests which will verify that your implementations provide outputs with the appropriate types and shapes required for our hidden tests. You can run these same public tests through [LabTS](https://teaching.doc.ic.ac.uk/labts) when you have finished your work, to check that we get the same results when running these public tests.\n",
        "\n",
        "Hidden tests will be ran after the submission deadline, and cannot be accessed :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coCfPKpSSuhz"
      },
      "source": [
        "### Setting up working environment \n",
        "\n",
        "For this coursework you will need to train a large network, therefore we recommend you work with Google Colaboratory or Paperspace, where you can access GPUs. \n",
        "\n",
        "#### Paperspace\n",
        "See [the Paperspace information doc](https://hackmd.io/@afspies/S1stL8Qnt). \n",
        "\n",
        "The public tests are embedded within the notebook and you can ignore the **tests** folder\n",
        "\n",
        "#### Google Colab\n",
        "To run this notebook on Google Colab, please log in to your account and go to the following page: https://colab.research.google.com. Then upload this notebook.\n",
        "\n",
        "For GPU support, go to \"Edit\" -> \"Notebook Settings\", and select \"Hardware accelerator\" as \"GPU\".\n",
        "\n",
        "**To run the public tests within colab** you will need to copy the \"tests\" folder to the ```/content/``` directory (this is the default working directory - you can also change directories with ```%cd```)\n",
        "\n",
        "#### Setup\n",
        "You will need to install pytorch and other libraries by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bxspn1oRSuh0",
        "outputId": "8456d1ca-e094-40ff-d672-f47767fcdc00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 165 kB 12.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 117 kB 50.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 45.3 MB/s \n",
            "\u001b[?25h  Building wheel for pandoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q otter-grader pandoc torch torchvision sklearn seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "53jMRaMRuW4_"
      },
      "outputs": [],
      "source": [
        "# Initialization Cell\n",
        "import otter\n",
        "grader = otter.Notebook(\"dl_cw_1.ipynb\")\n",
        "import matplotlib.pyplot as plt # DO NOT use %matplotlib inline in the notebook\n",
        "import numpy as np\n",
        "rng_seed = 90"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9Wj8-TMuW5I"
      },
      "source": [
        "## Introduction\n",
        "In this courswork you will explore various deep learning functionalities through implementing a number of pytorch neural network operations/layers and creating your own deep learning model and methodology for a high dimensional classification problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FjLiYiIuW5K"
      },
      "source": [
        "#### Intended learning outcomes\n",
        "- An understanding of the mechanics behind convolutional, pooling, linear and batch norm operations. \n",
        "- Be able to implement convolution, pooling, linear and batch norm layers from basic building blocks.\n",
        "- Experience designing, implementing and optimising a classifier for a high dimensional dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RA-GseZuW5Q"
      },
      "source": [
        "## Part 1 (50 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OplG2ZNZuW5S"
      },
      "source": [
        "In this part, you will use basic pytorch operations to define the 2D convolution, 2D max pooling, linear layer as well as 2D batch normalization operations. Being computer scientists we care about efficiency, we therefore do not what to see any _for loops_!\n",
        "\n",
        "**Your Task**\n",
        "- implement the forward pass for Conv2D (15 points), MaxPool2D (15 points), Linear (5 points) and BatchNorm2d (15 points)\n",
        "- You are **NOT** allowed to use the torch.nn modules (The one exception is that the class inherits from nn.Module)\n",
        "\n",
        "_hint: check out F.unfold and F.fold, they may be helpful_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "b2FymI-duW5W",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class Conv2d(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 stride=1,\n",
        "                 padding=0,\n",
        "                 bias=True):\n",
        "\n",
        "        super(Conv2d, self).__init__()\n",
        "        \"\"\"\n",
        "        An implementation of a convolutional layer.\n",
        "\n",
        "        The input consists of N data points, each with C channels, height H and\n",
        "        width W. We convolve each input with F different filters, where each filter\n",
        "        spans all C channels and has height HH and width WW.\n",
        "\n",
        "        Parameters:\n",
        "        - w: Filter weights of shape (F, C, HH, WW)\n",
        "        - b: Biases, of shape (F,)\n",
        "        - kernel_size: Size of the convolving kernel\n",
        "        - stride: The number of pixels between adjacent receptive fields in the\n",
        "            horizontal and vertical directions.\n",
        "        - padding: The number of pixels that will be used to zero-pad the input.\n",
        "        \"\"\"\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        # TODO: Define the parameters used in the forward pass\n",
        "\n",
        "        # if type(kernel_size) is int:\n",
        "        #   self.kernel_size = (kernel_size, kernel_size)\n",
        "        # else:\n",
        "        #   self.kernel_size = kernel_size\n",
        "\n",
        "        # Weights should have shape [out_channels, in_channels, kernel_x, kernel_y]\n",
        "        self.w = torch.rand(out_channels, in_channels, self.kernel_size[0], self.kernel_size[1])\n",
        "        # Bias should have shape [out_channels] \n",
        "        # self.bias = bias\n",
        "        if bias:\n",
        "          self.b=torch.rand((out_channels),)\n",
        "        else:\n",
        "          self.b=torch.zeros((out_channels),) \n",
        "\n",
        "\n",
        "        self.F = out_channels\n",
        "        self.C = in_channels\n",
        "        if type(kernel_size) is int:\n",
        "          self.kernel_size = (kernel_size, kernel_size)\n",
        "        else:\n",
        "          self.kernel_size = kernel_size\n",
        "        if isinstance(stride, int):\n",
        "          self.stride = (stride, stride)\n",
        "        else:\n",
        "          self.stride = stride\n",
        "\n",
        "        # self.stride = stride\n",
        "        if isinstance(padding, int):\n",
        "          self.padding = (padding, padding)\n",
        "        else:\n",
        "          self.padding = padding\n",
        "        # self.padding = padding\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "        - x: Input data of shape (N, C, H, W)\n",
        "        Output:\n",
        "        - out: Output data, of shape (N, F, H', W').\n",
        "        \"\"\"\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        # TODO: Implement the forward pass                                     #\n",
        "        N, C, H, W = x.shape\n",
        "        xuf = nn.unfold(x,kernel_size = self.kernel_size, padding = self.padding, stride = self.stride)\n",
        "\n",
        "        out= (xuf.transpose(1,2) @ (self.w.reshape([self.w.size(0),-1]).t())+self.b)\n",
        "        out=out.transpose(1,2)\n",
        "        \n",
        "        Hout = int(   (H - (self.w.shape[2]-1)-1 + (self.padding[0])*2)   / self.stride[0] + 1)\n",
        "        Wout = int(   (W - (self.w.shape[3]-1)-1 + (self.padding[1])*2)   / self.stride[1] + 1)\n",
        "\n",
        "        out = out.reshape([x.shape[0], self.F, Hout, Wout])\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XIWt1JCaSuh4",
        "outputId": "46266a6e-b00f-49f8-8b19-465c2b6fa81d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<p><strong style='color: red;'><pre style='display: inline;'>Convolution Layer</pre> results:</strong></p><p><strong><pre style='display: inline;'>Convolution Layer - 1</pre> result:</strong></p><pre>    Trying:\n",
              "        list(Conv2d(3,7,9)(torch.zeros((10, 3,64,64))).shape) == [10,7,56,56]\n",
              "    Expecting:\n",
              "        True\n",
              "    **********************************************************************\n",
              "    Line 1, in Convolution Layer 0\n",
              "    Failed example:\n",
              "        list(Conv2d(3,7,9)(torch.zeros((10, 3,64,64))).shape) == [10,7,56,56]\n",
              "    Exception raised:\n",
              "        Traceback (most recent call last):\n",
              "          File \"/usr/lib/python3.7/doctest.py\", line 1337, in __run\n",
              "            compileflags, 1), test.globs)\n",
              "          File \"<doctest Convolution Layer 0[0]>\", line 1, in <module>\n",
              "            list(Conv2d(3,7,9)(torch.zeros((10, 3,64,64))).shape) == [10,7,56,56]\n",
              "          File \"<ipython-input-32-2956a071cf0d>\", line 40, in __init__\n",
              "            self.w = torch.rand(out_channels, in_channels, self.kernel_size[0], self.kernel_size[1])\n",
              "          File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1178, in __getattr__\n",
              "            type(self).__name__, name))\n",
              "        AttributeError: 'Conv2d' object has no attribute 'kernel_size'\n",
              "</pre><p><strong><pre style='display: inline;'>Convolution Layer - 2</pre> result:</strong></p><pre>    Trying:\n",
              "        type(Conv2d(1,3,2)(torch.zeros((7,1,32,32)))) in [torch.Tensor, torch.nn.Parameter]\n",
              "    Expecting:\n",
              "        True\n",
              "    **********************************************************************\n",
              "    Line 1, in Convolution Layer 1\n",
              "    Failed example:\n",
              "        type(Conv2d(1,3,2)(torch.zeros((7,1,32,32)))) in [torch.Tensor, torch.nn.Parameter]\n",
              "    Exception raised:\n",
              "        Traceback (most recent call last):\n",
              "          File \"/usr/lib/python3.7/doctest.py\", line 1337, in __run\n",
              "            compileflags, 1), test.globs)\n",
              "          File \"<doctest Convolution Layer 1[0]>\", line 1, in <module>\n",
              "            type(Conv2d(1,3,2)(torch.zeros((7,1,32,32)))) in [torch.Tensor, torch.nn.Parameter]\n",
              "          File \"<ipython-input-32-2956a071cf0d>\", line 40, in __init__\n",
              "            self.w = torch.rand(out_channels, in_channels, self.kernel_size[0], self.kernel_size[1])\n",
              "          File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1178, in __getattr__\n",
              "            type(self).__name__, name))\n",
              "        AttributeError: 'Conv2d' object has no attribute 'kernel_size'\n",
              "</pre><p><strong><pre style='display: inline;'>Convolution Layer - 3</pre> result:</strong></p><pre>    Trying:\n",
              "        hasattr(Conv2d(1,1,1), 'w') and hasattr(Conv2d(1,1,1), 'b')\n",
              "    Expecting:\n",
              "        True\n",
              "    **********************************************************************\n",
              "    Line 1, in Convolution Layer 2\n",
              "    Failed example:\n",
              "        hasattr(Conv2d(1,1,1), 'w') and hasattr(Conv2d(1,1,1), 'b')\n",
              "    Exception raised:\n",
              "        Traceback (most recent call last):\n",
              "          File \"/usr/lib/python3.7/doctest.py\", line 1337, in __run\n",
              "            compileflags, 1), test.globs)\n",
              "          File \"<doctest Convolution Layer 2[0]>\", line 1, in <module>\n",
              "            hasattr(Conv2d(1,1,1), 'w') and hasattr(Conv2d(1,1,1), 'b')\n",
              "          File \"<ipython-input-32-2956a071cf0d>\", line 40, in __init__\n",
              "            self.w = torch.rand(out_channels, in_channels, self.kernel_size[0], self.kernel_size[1])\n",
              "          File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1178, in __getattr__\n",
              "            type(self).__name__, name))\n",
              "        AttributeError: 'Conv2d' object has no attribute 'kernel_size'\n",
              "</pre><p><strong><pre style='display: inline;'>Convolution Layer - 4</pre> result:</strong></p><pre>    Trying:\n",
              "        layer = Conv2d(7,32,4)\n",
              "    Expecting nothing\n",
              "    **********************************************************************\n",
              "    Line 1, in Convolution Layer 3\n",
              "    Failed example:\n",
              "        layer = Conv2d(7,32,4)\n",
              "    Exception raised:\n",
              "        Traceback (most recent call last):\n",
              "          File \"/usr/lib/python3.7/doctest.py\", line 1337, in __run\n",
              "            compileflags, 1), test.globs)\n",
              "          File \"<doctest Convolution Layer 3[0]>\", line 1, in <module>\n",
              "            layer = Conv2d(7,32,4)\n",
              "          File \"<ipython-input-32-2956a071cf0d>\", line 40, in __init__\n",
              "            self.w = torch.rand(out_channels, in_channels, self.kernel_size[0], self.kernel_size[1])\n",
              "          File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1178, in __getattr__\n",
              "            type(self).__name__, name))\n",
              "        AttributeError: 'Conv2d' object has no attribute 'kernel_size'\n",
              "    Trying:\n",
              "        (list(layer.w.shape) == [32,7,4,4])  and (list(layer.b.shape) == [32])\n",
              "    Expecting:\n",
              "        True\n",
              "    **********************************************************************\n",
              "    Line 2, in Convolution Layer 3\n",
              "    Failed example:\n",
              "        (list(layer.w.shape) == [32,7,4,4])  and (list(layer.b.shape) == [32])\n",
              "    Exception raised:\n",
              "        Traceback (most recent call last):\n",
              "          File \"/usr/lib/python3.7/doctest.py\", line 1337, in __run\n",
              "            compileflags, 1), test.globs)\n",
              "          File \"<doctest Convolution Layer 3[1]>\", line 1, in <module>\n",
              "            (list(layer.w.shape) == [32,7,4,4])  and (list(layer.b.shape) == [32])\n",
              "        NameError: name 'layer' is not defined\n",
              "</pre>"
            ],
            "text/plain": [
              "Convolution Layer results:\n",
              "    Convolution Layer - 1 result:\n",
              "        Trying:\n",
              "            list(Conv2d(3,7,9)(torch.zeros((10, 3,64,64))).shape) == [10,7,56,56]\n",
              "        Expecting:\n",
              "            True\n",
              "        **********************************************************************\n",
              "        Line 1, in Convolution Layer 0\n",
              "        Failed example:\n",
              "            list(Conv2d(3,7,9)(torch.zeros((10, 3,64,64))).shape) == [10,7,56,56]\n",
              "        Exception raised:\n",
              "            Traceback (most recent call last):\n",
              "              File \"/usr/lib/python3.7/doctest.py\", line 1337, in __run\n",
              "                compileflags, 1), test.globs)\n",
              "              File \"<doctest Convolution Layer 0[0]>\", line 1, in <module>\n",
              "                list(Conv2d(3,7,9)(torch.zeros((10, 3,64,64))).shape) == [10,7,56,56]\n",
              "              File \"<ipython-input-32-2956a071cf0d>\", line 40, in __init__\n",
              "                self.w = torch.rand(out_channels, in_channels, self.kernel_size[0], self.kernel_size[1])\n",
              "              File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1178, in __getattr__\n",
              "                type(self).__name__, name))\n",
              "            AttributeError: 'Conv2d' object has no attribute 'kernel_size'\n",
              "\n",
              "    Convolution Layer - 2 result:\n",
              "        Trying:\n",
              "            type(Conv2d(1,3,2)(torch.zeros((7,1,32,32)))) in [torch.Tensor, torch.nn.Parameter]\n",
              "        Expecting:\n",
              "            True\n",
              "        **********************************************************************\n",
              "        Line 1, in Convolution Layer 1\n",
              "        Failed example:\n",
              "            type(Conv2d(1,3,2)(torch.zeros((7,1,32,32)))) in [torch.Tensor, torch.nn.Parameter]\n",
              "        Exception raised:\n",
              "            Traceback (most recent call last):\n",
              "              File \"/usr/lib/python3.7/doctest.py\", line 1337, in __run\n",
              "                compileflags, 1), test.globs)\n",
              "              File \"<doctest Convolution Layer 1[0]>\", line 1, in <module>\n",
              "                type(Conv2d(1,3,2)(torch.zeros((7,1,32,32)))) in [torch.Tensor, torch.nn.Parameter]\n",
              "              File \"<ipython-input-32-2956a071cf0d>\", line 40, in __init__\n",
              "                self.w = torch.rand(out_channels, in_channels, self.kernel_size[0], self.kernel_size[1])\n",
              "              File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1178, in __getattr__\n",
              "                type(self).__name__, name))\n",
              "            AttributeError: 'Conv2d' object has no attribute 'kernel_size'\n",
              "\n",
              "    Convolution Layer - 3 result:\n",
              "        Trying:\n",
              "            hasattr(Conv2d(1,1,1), 'w') and hasattr(Conv2d(1,1,1), 'b')\n",
              "        Expecting:\n",
              "            True\n",
              "        **********************************************************************\n",
              "        Line 1, in Convolution Layer 2\n",
              "        Failed example:\n",
              "            hasattr(Conv2d(1,1,1), 'w') and hasattr(Conv2d(1,1,1), 'b')\n",
              "        Exception raised:\n",
              "            Traceback (most recent call last):\n",
              "              File \"/usr/lib/python3.7/doctest.py\", line 1337, in __run\n",
              "                compileflags, 1), test.globs)\n",
              "              File \"<doctest Convolution Layer 2[0]>\", line 1, in <module>\n",
              "                hasattr(Conv2d(1,1,1), 'w') and hasattr(Conv2d(1,1,1), 'b')\n",
              "              File \"<ipython-input-32-2956a071cf0d>\", line 40, in __init__\n",
              "                self.w = torch.rand(out_channels, in_channels, self.kernel_size[0], self.kernel_size[1])\n",
              "              File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1178, in __getattr__\n",
              "                type(self).__name__, name))\n",
              "            AttributeError: 'Conv2d' object has no attribute 'kernel_size'\n",
              "\n",
              "    Convolution Layer - 4 result:\n",
              "        Trying:\n",
              "            layer = Conv2d(7,32,4)\n",
              "        Expecting nothing\n",
              "        **********************************************************************\n",
              "        Line 1, in Convolution Layer 3\n",
              "        Failed example:\n",
              "            layer = Conv2d(7,32,4)\n",
              "        Exception raised:\n",
              "            Traceback (most recent call last):\n",
              "              File \"/usr/lib/python3.7/doctest.py\", line 1337, in __run\n",
              "                compileflags, 1), test.globs)\n",
              "              File \"<doctest Convolution Layer 3[0]>\", line 1, in <module>\n",
              "                layer = Conv2d(7,32,4)\n",
              "              File \"<ipython-input-32-2956a071cf0d>\", line 40, in __init__\n",
              "                self.w = torch.rand(out_channels, in_channels, self.kernel_size[0], self.kernel_size[1])\n",
              "              File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1178, in __getattr__\n",
              "                type(self).__name__, name))\n",
              "            AttributeError: 'Conv2d' object has no attribute 'kernel_size'\n",
              "        Trying:\n",
              "            (list(layer.w.shape) == [32,7,4,4])  and (list(layer.b.shape) == [32])\n",
              "        Expecting:\n",
              "            True\n",
              "        **********************************************************************\n",
              "        Line 2, in Convolution Layer 3\n",
              "        Failed example:\n",
              "            (list(layer.w.shape) == [32,7,4,4])  and (list(layer.b.shape) == [32])\n",
              "        Exception raised:\n",
              "            Traceback (most recent call last):\n",
              "              File \"/usr/lib/python3.7/doctest.py\", line 1337, in __run\n",
              "                compileflags, 1), test.globs)\n",
              "              File \"<doctest Convolution Layer 3[1]>\", line 1, in <module>\n",
              "                (list(layer.w.shape) == [32,7,4,4])  and (list(layer.b.shape) == [32])\n",
              "            NameError: name 'layer' is not defined"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "grader.check(\"Convolution Layer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ThrRIjf9uW5a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MaxPool2d(nn.Module):\n",
        "    def __init__(self, kernel_size):\n",
        "        super(MaxPool2d, self).__init__()\n",
        "        \"\"\"\n",
        "        An implementation of a max-pooling layer.\n",
        "\n",
        "        Parameters:\n",
        "        - kernel_size: the size of the window to take a max over\n",
        "        \"\"\"\n",
        "        # TODO: Define the parameters used in the forward pass                 #\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        if isinstance(kernel_size, int):\n",
        "          self.kernel_size = (kernel_size, kernel_size)\n",
        "        else:\n",
        "          self.kernel_size = kernel_size\n",
        "        self.munfold = nn.Unfold(kernel_size = self.kernel_size, stride = self.kernel_size)\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "        - x: Input data of shape (N, C, H, W)\n",
        "        Output:\n",
        "        - out: Output data, of shape (N, C, H', W').\n",
        "        \"\"\"\n",
        "        # TODO: Implement the forward pass                                     #\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        N, C, H, W = x.shape\n",
        "        \n",
        "        fout = self.munfold(x.transpose(1,2))\n",
        "        fout = torch.reshape(fout,(*fout.shape[:2],C,self.kernel_size[0]*self.kernel_size[1]))\n",
        "        fout=torch.max(fout,-1)[0].transpose(1,2)\n",
        "\n",
        "        Hout = (H - (self.kernel_size[0]-1)-1 ) // self.stride[0] + 1\n",
        "        Wout = (W - (self.kernel_size[1]-1)-1 ) // self.stride[1] + 1\n",
        "\n",
        "        out = fout.view(x.shape[0], C, Hout, Wout)\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "i1ntLmMuSuh4",
        "outputId": "e2ae123c-c0c8-420d-8962-92e1efed8389"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<p><strong style='color: red;'><pre style='display: inline;'>MaxPool Layer</pre> results:</strong></p><p><strong><pre style='display: inline;'>MaxPool Layer - 1</pre> result:</strong></p><pre>    Trying:\n",
              "        list(MaxPool2d(3)(torch.zeros((10,3,64,64))).shape) == [10,3,21,21]\n",
              "    Expecting:\n",
              "        True\n",
              "    **********************************************************************\n",
              "    Line 1, in MaxPool Layer 0\n",
              "    Failed example:\n",
              "        list(MaxPool2d(3)(torch.zeros((10,3,64,64))).shape) == [10,3,21,21]\n",
              "    Exception raised:\n",
              "        Traceback (most recent call last):\n",
              "          File \"/usr/lib/python3.7/doctest.py\", line 1337, in __run\n",
              "            compileflags, 1), test.globs)\n",
              "          File \"<doctest MaxPool Layer 0[0]>\", line 1, in <module>\n",
              "            list(MaxPool2d(3)(torch.zeros((10,3,64,64))).shape) == [10,3,21,21]\n",
              "          File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
              "            return forward_call(*input, **kwargs)\n",
              "          File \"<ipython-input-54-1d1886d5a254>\", line 36, in forward\n",
              "            fout = torch.reshape(fout,(*fout.shape[:2],C,self.kernel_size[0]*self.kernel_size[1]))\n",
              "        RuntimeError: shape '[10, 576, 3, 9]' is invalid for input of size 120960\n",
              "</pre><p><strong><pre style='display: inline;'>MaxPool Layer - 2</pre> result:</strong></p><pre>    Trying:\n",
              "        type(MaxPool2d(3)(torch.zeros((10,3,64,64)))) in [torch.Tensor]\n",
              "    Expecting:\n",
              "        True\n",
              "    **********************************************************************\n",
              "    Line 1, in MaxPool Layer 1\n",
              "    Failed example:\n",
              "        type(MaxPool2d(3)(torch.zeros((10,3,64,64)))) in [torch.Tensor]\n",
              "    Exception raised:\n",
              "        Traceback (most recent call last):\n",
              "          File \"/usr/lib/python3.7/doctest.py\", line 1337, in __run\n",
              "            compileflags, 1), test.globs)\n",
              "          File \"<doctest MaxPool Layer 1[0]>\", line 1, in <module>\n",
              "            type(MaxPool2d(3)(torch.zeros((10,3,64,64)))) in [torch.Tensor]\n",
              "          File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
              "            return forward_call(*input, **kwargs)\n",
              "          File \"<ipython-input-54-1d1886d5a254>\", line 36, in forward\n",
              "            fout = torch.reshape(fout,(*fout.shape[:2],C,self.kernel_size[0]*self.kernel_size[1]))\n",
              "        RuntimeError: shape '[10, 576, 3, 9]' is invalid for input of size 120960\n",
              "</pre>"
            ],
            "text/plain": [
              "MaxPool Layer results:\n",
              "    MaxPool Layer - 1 result:\n",
              "        Trying:\n",
              "            list(MaxPool2d(3)(torch.zeros((10,3,64,64))).shape) == [10,3,21,21]\n",
              "        Expecting:\n",
              "            True\n",
              "        **********************************************************************\n",
              "        Line 1, in MaxPool Layer 0\n",
              "        Failed example:\n",
              "            list(MaxPool2d(3)(torch.zeros((10,3,64,64))).shape) == [10,3,21,21]\n",
              "        Exception raised:\n",
              "            Traceback (most recent call last):\n",
              "              File \"/usr/lib/python3.7/doctest.py\", line 1337, in __run\n",
              "                compileflags, 1), test.globs)\n",
              "              File \"<doctest MaxPool Layer 0[0]>\", line 1, in <module>\n",
              "                list(MaxPool2d(3)(torch.zeros((10,3,64,64))).shape) == [10,3,21,21]\n",
              "              File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
              "                return forward_call(*input, **kwargs)\n",
              "              File \"<ipython-input-54-1d1886d5a254>\", line 36, in forward\n",
              "                fout = torch.reshape(fout,(*fout.shape[:2],C,self.kernel_size[0]*self.kernel_size[1]))\n",
              "            RuntimeError: shape '[10, 576, 3, 9]' is invalid for input of size 120960\n",
              "\n",
              "    MaxPool Layer - 2 result:\n",
              "        Trying:\n",
              "            type(MaxPool2d(3)(torch.zeros((10,3,64,64)))) in [torch.Tensor]\n",
              "        Expecting:\n",
              "            True\n",
              "        **********************************************************************\n",
              "        Line 1, in MaxPool Layer 1\n",
              "        Failed example:\n",
              "            type(MaxPool2d(3)(torch.zeros((10,3,64,64)))) in [torch.Tensor]\n",
              "        Exception raised:\n",
              "            Traceback (most recent call last):\n",
              "              File \"/usr/lib/python3.7/doctest.py\", line 1337, in __run\n",
              "                compileflags, 1), test.globs)\n",
              "              File \"<doctest MaxPool Layer 1[0]>\", line 1, in <module>\n",
              "                type(MaxPool2d(3)(torch.zeros((10,3,64,64)))) in [torch.Tensor]\n",
              "              File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
              "                return forward_call(*input, **kwargs)\n",
              "              File \"<ipython-input-54-1d1886d5a254>\", line 36, in forward\n",
              "                fout = torch.reshape(fout,(*fout.shape[:2],C,self.kernel_size[0]*self.kernel_size[1]))\n",
              "            RuntimeError: shape '[10, 576, 3, 9]' is invalid for input of size 120960"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "grader.check(\"MaxPool Layer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "t4jqNUbguW5d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bias=True):\n",
        "        super(Linear, self).__init__()\n",
        "        \"\"\"\n",
        "        An implementation of a Linear layer.\n",
        "\n",
        "        Parameters:\n",
        "        - weight: the learnable weights of the module of shape (in_channels, out_channels).\n",
        "        - bias: the learnable bias of the module of shape (out_channels).\n",
        "        \"\"\"\n",
        "        # TODO: Define the parameters used in the forward pass                 #\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        # self.register_parameter is not used as it was mentioned on piazza\n",
        "        # that this will be overridden\n",
        "        # Also no initialisation methods for this reason\n",
        "        self.w = torch.rand((in_channels, out_channels),)\n",
        "\n",
        "        if bias:\n",
        "          self.b=torch.rand((out_channels),)\n",
        "        else:\n",
        "          self.b=torch.zeros((out_channels),)          \n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "        - x: Input data of shape (N, *, H) where * means any number of additional\n",
        "        dimensions and H = in_channels\n",
        "        Output:\n",
        "        - out: Output data of shape (N, *, H') where * means any number of additional\n",
        "        dimensions and H' = out_channels\n",
        "        \"\"\"\n",
        "        # TODO: Implement the forward pass                                     #\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        out = torch.matmul(x, self.w)+self.b\n",
        "        \n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "TE97CYPrSuh5",
        "outputId": "04be8052-5b6b-4a18-dfbd-fa5706314446"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<p><strong><pre style='display: inline;'>Linear Layer</pre></strong> passed!</p>"
            ],
            "text/plain": [
              "Linear Layer results: All test cases passed!"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "grader.check(\"Linear Layer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "je2rfaENuW5f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class BatchNorm2d(nn.Module):\n",
        "    def __init__(self, num_features, eps=1e-05, momentum=0.1):\n",
        "        super(BatchNorm2d, self).__init__()\n",
        "        \"\"\"\n",
        "        An implementation of a Batch Normalization over a mini-batch of 2D inputs.\n",
        "\n",
        "        The mean and standard-deviation are calculated per-dimension over the\n",
        "        mini-batches and gamma and beta are learnable parameter vectors of\n",
        "        size num_features.\n",
        "\n",
        "        Parameters:\n",
        "        - num_features: C from an expected input of size (N, C, H, W).\n",
        "        - eps: a value added to the denominator for numerical stability. Default: 1e-5\n",
        "        - momentum: momentum – the value used for the running_mean and running_var\n",
        "        computation. Default: 0.1\n",
        "        - gamma: the learnable weights of shape (num_features).\n",
        "        - beta: the learnable bias of the module of shape (num_features).\n",
        "        \"\"\"\n",
        "        # TODO: Define the parameters used in the forward pass                 #\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "\n",
        "        # self.register_parameter is not used as it was mentioned on piazza\n",
        "        # that this will be overridden\n",
        "        self.gamma = torch.ones((num_features), requires_grad = True)\n",
        "        self.beta = torch.zeros((num_features), requires_grad = True)        \n",
        "        self.moving_avg = torch.zeros([1,num_features,1,1])\n",
        "        self.moving_var = torch.zeros([1,num_features,1,1])\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        During training this layer keeps running estimates of its computed mean and\n",
        "        variance, which are then used for normalization during evaluation.\n",
        "        Input:\n",
        "        - x: Input data of shape (N, C, H, W)\n",
        "        Output:\n",
        "        - out: Output data of shape (N, C, H, W) (same shape as input)\n",
        "        \"\"\"\n",
        "        # TODO: Implement the forward pass                                     #\n",
        "        #       (be aware of the difference for training and testing)          #\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        # Test\n",
        "        if not self.training :\n",
        "          x = (x - self.moving_avg) / torch.sqrt(self.moving_var + self.eps)\n",
        "          x = self.gamma.reshape([1, self.num_features, 1, 1])* x + self.beta.reshape([1, self.num_features, 1, 1])\n",
        "        # Train\n",
        "        else:\n",
        "          batch_avg = x.mean(dim = (0,2,3), keepdim = True)\n",
        "          batch_var = x.var(dim = (0,2,3), unbiased = False, keepdim = True)\n",
        "\n",
        "          x = (x - batch_avg)/torch.sqrt(batch_var + self.eps)\n",
        "          x = self.gamma.reshape([1, self.num_features, 1, 1])* x + self.beta.reshape([1, self.num_features, 1, 1])\n",
        "\n",
        "          self.moving_avg = (1.0 - self.momentum) * self.moving_avg + self.momentum * batch_avg\n",
        "          self.moving_var =  (1.0 - self.momentum) * self.moving_var + self.momentum * x.var(dim = (0,2,3), unbiased = True, keepdim = True)     \n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "deletable": false,
        "editable": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "px9Vl1voSuh5",
        "outputId": "89532d37-7bd4-4f6c-f0b0-1db913630169"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<p><strong><pre style='display: inline;'>BatchNorm Layer</pre></strong> passed!</p>"
            ],
            "text/plain": [
              "BatchNorm Layer results: All test cases passed!"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "grader.check(\"BatchNorm Layer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMQSFRNUuW5i"
      },
      "source": [
        "## Part 2 (40 points)\n",
        "\n",
        "In this part, you will design, train and optimise a custom deep learning model for classifying a specially selected subset of Imagenet. Termed NaturalImageNet, it is made up of a hand selected subset of the famous ImageNet dataset. The dataset contains 20 classes, all animals from the natural world. We hope that this dataset will be fun to work with but also a challenge.\n",
        "\n",
        "You will be marked on your experimental process, methods implemented and your reasoning behind your decisions. While there will be marks for exceeding a baseline performance score we stress that students should **NOT** spend excessive amounts of time optimising performance to silly levels.\n",
        "\n",
        "We have given you some starter code, please feel free to use and adapt it.\n",
        "\n",
        "**Your Task**\n",
        "1. Develop/adapt a deep learning pipeline to maximise performance on the test set. (30 points)\n",
        "    * 10 points will be awarded for improving on the baseline score on the test set. Don't worry you can get full marks here by improving by a minor amount.\n",
        "    * 20 points will be awarded for the adaptations made to the baseline model and pipeline.\n",
        "\n",
        "2. Answer the qualititative questions (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfh7tCyXUoTo"
      },
      "source": [
        "**Downloading NaturalImageNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsLO9QDMUoTo"
      },
      "outputs": [],
      "source": [
        "ON_COLAB = False\n",
        "\n",
        "!wget https://zenodo.org/record/5846979/files/NaturalImageNetTest.zip?download=1\n",
        "!wget https://zenodo.org/record/5846979/files/NaturalImageNetTrain.zip?download=1\n",
        "if ON_COLAB:\n",
        "    !unzip /content/NaturalImageNetTest.zip?download=1 > /dev/null\n",
        "    !unzip /content/NaturalImageNetTrain.zip?download=1 > /dev/null\n",
        "else: \n",
        "    !unzip NaturalImageNetTest.zip?download=1 > /dev/null\n",
        "    !unzip NaturalImageNetTrain.zip?download=1 > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im6LzJJ6uW5o"
      },
      "outputs": [],
      "source": [
        "#torch\n",
        "import torch\n",
        "from torch.nn import Conv2d, MaxPool2d\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "#other\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# set the seed for reproducibility\n",
        "rng_seed = 90\n",
        "torch.manual_seed(rng_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XuC3wCSUoTp"
      },
      "outputs": [],
      "source": [
        "# When we import the images we want to first convert them to a tensor. \n",
        "# It is also common in deep learning to normalise the the inputs. This \n",
        "# helps with stability.\n",
        "# To read more about this subject this article is a great one:\n",
        "# https://towardsdatascience.com/understand-data-normalization-in-machine-learning-8ff3062101f0\n",
        "\n",
        "# transforms is a useful pytorch package which contains a range of functions\n",
        "# for preprocessing data, for example applying data augmentation to images \n",
        "# (random rotations, blurring the image, randomly cropping the image). To find out\n",
        "# more please refer to the pytorch documentation:\n",
        "# https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        "\n",
        "mean = torch.Tensor([0.485, 0.456, 0.406])\n",
        "std = torch.Tensor([0.229, 0.224, 0.225])\n",
        "transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(256),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean.tolist(), std.tolist()),\n",
        "        ]\n",
        "    )\n",
        "train_path = ('/content/' if ON_COLAB else '') + 'NaturalImageNetTrain'\n",
        "test_path = ('/content/' if ON_COLAB else '') +'NaturalImageNetTest'\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(test_path, transform=transform)\n",
        "\n",
        "# Create train val split\n",
        "n = len(train_dataset)\n",
        "n_val = int(n/10)\n",
        "\n",
        "train_set, val_set = torch.utils.data.random_split(train_dataset, [n-n_val, n_val])\n",
        "\n",
        "\n",
        "print(len(train_set), len(val_set), len(test_dataset))\n",
        "\n",
        "\n",
        "# The number of images to process in one go. If you run out of GPU\n",
        "# memory reduce this number! \n",
        "batch_size = 128\n",
        "\n",
        "# Dataloaders are a great pytorch functionality for feeding data into our AI models.\n",
        "# see https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader\n",
        "# for more info.\n",
        "\n",
        "loader_train = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "loader_val = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "loader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwxm3jsxUoTq"
      },
      "outputs": [],
      "source": [
        "unnormalize = transforms.Normalize((-mean / std).tolist(), (1.0 / std).tolist())\n",
        "\n",
        "def denorm(x):\n",
        "    '''\n",
        "    Function to reverse the normalization so that we can visualise the outputs\n",
        "    '''\n",
        "    x = unnormalize(x)\n",
        "    x = x.view(x.size(0), 3, 256, 256)\n",
        "    return x\n",
        "\n",
        "def show(img):\n",
        "    '''\n",
        "    function to visualise tensors\n",
        "    '''\n",
        "    if torch.cuda.is_available():\n",
        "        img = img.cpu()\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)).clip(0, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gLtEaOIUoTq"
      },
      "source": [
        "**Visualising some example images** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtlftLPjUoTq"
      },
      "outputs": [],
      "source": [
        "sample_inputs, _ = next(iter(loader_val))\n",
        "fixed_input = sample_inputs[:27, :, :, :]\n",
        "\n",
        "img = make_grid(denorm(fixed_input), nrow=9, padding=2, normalize=False,\n",
        "                value_range=None, scale_each=False, pad_value=0)\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.axis('off')\n",
        "show(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMtUxmIPSuh7"
      },
      "source": [
        "Next, we define ResNet-18:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bknm_PrxuW5r"
      },
      "outputs": [],
      "source": [
        "# define resnet building blocks\n",
        "\n",
        "class ResidualBlock(nn.Module): \n",
        "    def __init__(self, inchannel, outchannel, stride=1): \n",
        "        \n",
        "        super(ResidualBlock, self).__init__() \n",
        "        \n",
        "        self.left = nn.Sequential(Conv2d(inchannel, outchannel, kernel_size=3, \n",
        "                                         stride=stride, padding=1, bias=False), \n",
        "                                  nn.BatchNorm2d(outchannel), \n",
        "                                  nn.ReLU(inplace=True), \n",
        "                                  Conv2d(outchannel, outchannel, kernel_size=3, \n",
        "                                         stride=1, padding=1, bias=False), \n",
        "                                  nn.BatchNorm2d(outchannel)) \n",
        "        \n",
        "        self.shortcut = nn.Sequential() \n",
        "        \n",
        "        if stride != 1 or inchannel != outchannel: \n",
        "            \n",
        "            self.shortcut = nn.Sequential(Conv2d(inchannel, outchannel, \n",
        "                                                 kernel_size=1, stride=stride, \n",
        "                                                 padding = 0, bias=False), \n",
        "                                          nn.BatchNorm2d(outchannel) ) \n",
        "            \n",
        "    def forward(self, x): \n",
        "        \n",
        "        out = self.left(x) \n",
        "        \n",
        "        out += self.shortcut(x) \n",
        "        \n",
        "        out = F.relu(out) \n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "    \n",
        "# define resnet\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, ResidualBlock, num_classes = 20):\n",
        "        \n",
        "        super(ResNet, self).__init__()\n",
        "        \n",
        "        self.inchannel = 16\n",
        "        self.conv1 = nn.Sequential(Conv2d(3, 16, kernel_size = 3, stride = 1,\n",
        "                                            padding = 1, bias = False), \n",
        "                                  nn.BatchNorm2d(16), \n",
        "                                  nn.ReLU())\n",
        "        \n",
        "        self.layer1 = self.make_layer(ResidualBlock, 16, 2, stride = 2)\n",
        "        self.layer2 = self.make_layer(ResidualBlock, 32, 2, stride = 2)\n",
        "        self.layer3 = self.make_layer(ResidualBlock, 64, 2, stride = 2)\n",
        "        self.layer4 = self.make_layer(ResidualBlock, 128, 2, stride = 2)\n",
        "        self.layer5 = self.make_layer(ResidualBlock, 256, 2, stride = 2)\n",
        "        self.layer6 = self.make_layer(ResidualBlock, 512, 2, stride = 2)\n",
        "        self.maxpool = MaxPool2d(4)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "        \n",
        "    \n",
        "    def make_layer(self, block, channels, num_blocks, stride):\n",
        "        \n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        \n",
        "        layers = []\n",
        "        \n",
        "        for stride in strides:\n",
        "            \n",
        "            layers.append(block(self.inchannel, channels, stride))\n",
        "            \n",
        "            self.inchannel = channels\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        x = self.layer6(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "    \n",
        "# please do not change the name of this class\n",
        "def MyResNet():\n",
        "    return ResNet(ResidualBlock)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ujAcIPbix75"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def confusion(preds, y):\n",
        "  labels = ['African Elephant', 'Kingfisher', 'Deer','Brown Bear', 'Chameleon', 'Dragonfly',\n",
        "    'Giant Panda', 'Gorilla', 'Hawk', 'King Penguin', 'Koala', 'Ladybug', 'Lion',\n",
        "    'Meerkat', 'Orangutan', 'Peacock', 'Red Fox', 'Snail', 'Tiger', 'White Rhino']\n",
        "  # Plotting the confusion matrix\n",
        "  cm = confusion_matrix(y.cpu().numpy(), preds.cpu().numpy(), normalize='true')\n",
        "  fig, ax= plt.subplots(1, 1, figsize=(15,10))\n",
        "  sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
        "\n",
        "  # labels, title and ticks\n",
        "  ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "  ax.set_title('Confusion Matrix');\n",
        "  ax.xaxis.set_ticklabels(labels, rotation = 70); ax.yaxis.set_ticklabels(labels, rotation=0);\n",
        "  plt.show()\n",
        "\n",
        "def incorrect_preds(preds, y, test_img):\n",
        "  labels = ['African Elephant', 'Kingfisher', 'Deer','Brown Bear', 'Chameleon', 'Dragonfly',\n",
        "    'Giant Panda', 'Gorilla', 'Hawk', 'King Penguin', 'Koala', 'Ladybug', 'Lion',\n",
        "    'Meerkat', 'Orangutan', 'Peacock', 'Red Fox', 'Snail', 'Tiger', 'White Rhino']\n",
        "  # lets see a sample of the images which were classified incorrectly!\n",
        "  correct = (preds == y).float()\n",
        "  test_labels_check = correct.cpu().numpy()\n",
        "  incorrect_indexes = np.where(test_labels_check == 0)\n",
        "\n",
        "  test_img = test_img.cpu()\n",
        "  samples = make_grid(denorm(test_img[incorrect_indexes][:9]), nrow=3,\n",
        "                      padding=2, normalize=False, value_range=None, \n",
        "                      scale_each=False, pad_value=0)\n",
        "  plt.figure(figsize = (20,10))\n",
        "  plt.title('Incorrectly Classified Instances')\n",
        "  show(samples)\n",
        "  labels = np.asarray(labels)\n",
        "  print('Predicted label',labels[preds[incorrect_indexes].cpu().numpy()[:9]])\n",
        "  print('True label', labels[y[incorrect_indexes].cpu().numpy()[:9]])\n",
        "  print('Corresponding images are shown below')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AynHSTv3uW55"
      },
      "outputs": [],
      "source": [
        "USE_GPU = True\n",
        "dtype = torch.float32 \n",
        "\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(device)\n",
        "    \n",
        "\n",
        "print_every = 10\n",
        "def check_accuracy(loader, model, analysis=False):\n",
        "    # function for test accuracy on validation and test set\n",
        "    \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for t, (x, y) in enumerate(loader):\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            scores = model(x)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "            if t == 0 and analysis:\n",
        "              stack_labels = y\n",
        "              stack_predicts = preds\n",
        "            elif analysis:\n",
        "              stack_labels = torch.cat([stack_labels, y], 0)\n",
        "              stack_predicts = torch.cat([stack_predicts, preds], 0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct of val set (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "        if analysis:\n",
        "          print('check acc', type(stack_predicts), type(stack_labels))\n",
        "          confusion(stack_predicts, stack_labels)\n",
        "          incorrect_preds(preds, y, x)\n",
        "        return float(acc)\n",
        "\n",
        "        \n",
        "\n",
        "def train_part(model, optimizer, epochs=1):\n",
        "    \"\"\"\n",
        "    Train a model on NaturalImageNet using the PyTorch Module API.\n",
        "    \n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "    \n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    for e in range(epochs):\n",
        "        for t, (x, y) in enumerate(loader_train):\n",
        "            model.train()  # put model to training mode\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "            scores = model(x)\n",
        "            loss = F.cross_entropy(scores, y)\n",
        "\n",
        "            # Zero out all of the gradients for the variables which the optimizer\n",
        "            # will update.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the parameters of the model using the gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            if t % print_every == 0:\n",
        "                print('Epoch: %d, Iteration %d, loss = %.4f' % (e, t, loss.item()))\n",
        "        check_accuracy(loader_val, model)\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_6N1VZQuW58"
      },
      "outputs": [],
      "source": [
        "# define and train the network\n",
        "model = MyResNet()\n",
        "optimizer = optim.Adamax(model.parameters(), lr=0.0001, weight_decay=1e-7) \n",
        "\n",
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Total number of parameters is: {}\".format(params))\n",
        "\n",
        "train_part(model, optimizer, epochs = 10)\n",
        "\n",
        "\n",
        "# report test set accuracy\n",
        "check_accuracy(loader_val, model, analysis=True)\n",
        "\n",
        "\n",
        "# save the model\n",
        "torch.save(model.state_dict(), 'model.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1zE-k-kSuh9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvRr-1oISuh9"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "### Network Performance\n",
        "\n",
        "Run the code below when all engineering decisions have been made, do not overfit to the test set!\n",
        "\n",
        "**Note that** this will appear in the output, and be checked by markers (so ensure it is present in the auto-export)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-GqMA0VoHxj"
      },
      "outputs": [],
      "source": [
        "# Run once your have trained your final model\n",
        "check_accuracy(loader_test, model, analysis=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAYXOTpqSuh9"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB5ZE5KWSuh9"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "### Q2.1: Hyperparameter Search:\n",
        "Given such a network with a large number of trainable parameters, and a training set of a large number of data, what do you think is the best strategy for hyperparameter searching? (3 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5GxbsezSuh9"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN59yZNYSuh9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBSUSbHISuh9"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "### Q2.2: Engineering Decisions \n",
        "\n",
        "Detail which engineering decisions you made to boost the performance of the baseline results. Why do you think that they helped? (7 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxUl1hDESuh-"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeAym8hhSuh-"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nytiCnC2uW5_"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "## Part 3 (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x9b90b_Suh-"
      },
      "source": [
        "The code provided below will allow you to visualise the feature maps computed by different layers of your network. Run the code (install matplotlib if necessary) and **answer the following questions*(: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIfThkeYSuh-"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "### Q3.1 : Learned Features\n",
        "\n",
        "Compare the feature maps from low-level layers to high-level layers, what do you observe? (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_YTsIzwSuh-"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8P4TBQfSuh-"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAw7RTT2Suh-"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "### Q3.2: Performance Analysis\n",
        "\n",
        "Use the training log, reported test set accuracy and the feature maps, analyse the performance of your network. If you think the performance is sufficiently good, explain why; if not, what might be the problem and how can you improve the performance? (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brzMwfa-Suh-"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NMzuLquSuh-"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q8Rz1SdSuh-"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "### Q3.3: Alternative Evaluations\n",
        "\n",
        "What are the other possible ways to analyse the performance of your network? (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ_BwMJgSuh_"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU_zXO4NSuh_"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbk2R4J_Suh_"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "**Feature Visualization**\n",
        "\n",
        "The code below will visualize the features of your network layers (you may need to modify the layer names if you made changes to your architecture). \n",
        "\n",
        "If you change the plotting code, please ensure it still exports correctly when running the submission cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6RhVpjcSuh_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_model_features():\n",
        "    fig = plt.tight_layout()\n",
        "    activation = {}\n",
        "    def get_activation(name):\n",
        "        def hook(model, input, output):\n",
        "            activation[name] = output.detach()\n",
        "        return hook\n",
        "    vis_labels = ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'layer5', 'layer6']\n",
        "\n",
        "    for l in vis_labels:\n",
        "        getattr(model, l).register_forward_hook(get_activation(l))\n",
        "        \n",
        "\n",
        "    data, _ = test_dataset[999]\n",
        "    data = data.unsqueeze_(0).to(device = device, dtype = dtype)\n",
        "    output = model(data)\n",
        "\n",
        "    for idx, l in enumerate(vis_labels):\n",
        "        act = activation[l].squeeze()\n",
        "\n",
        "        # only showing the first 16 channels\n",
        "        ncols, nrows = 8, 2\n",
        "        \n",
        "        fig, axarr = plt.subplots(nrows, ncols, figsize=(15,5))\n",
        "        fig.suptitle(l)\n",
        "\n",
        "        count = 0\n",
        "        for i in range(nrows):\n",
        "            for j in range(ncols):\n",
        "                axarr[i, j].imshow(act[count].cpu())\n",
        "                axarr[i, j].axis('off')\n",
        "                count += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58ey3XPUSuh_"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxJhnmxnuW6B"
      },
      "outputs": [],
      "source": [
        "# Visualize the figure here, so it is exported nicely\n",
        "plot_model_features()  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y71osmrwSuh_"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "SzAMwLPiSuh_"
      },
      "source": [
        "---\n",
        "\n",
        "To double-check your work, the cell below will rerun all of the autograder tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "IW4Ivc5vSuh_"
      },
      "outputs": [],
      "source": [
        "grader.check_all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsLovslWSuiA"
      },
      "source": [
        "## Submission\n",
        "Git push your finalized version of this notebook (with saved outputs) to the gitlab repo which you were assigned. You should request our tests once and check that the ```preview.pdf```:\n",
        "* Passes all public tests (these are the same ones provided / embedded in the notebook itself)\n",
        "* Contains your qualitative answers\n",
        "* Contains your figures (confusion matrix and network features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7tOK_D3SuiA"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "dl_cw_1 (2).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "otter": {
      "tests": {
        "BatchNorm Layer": {
          "name": "BatchNorm Layer",
          "points": 15,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> list(BatchNorm2d(2)(torch.zeros((3,2,7,6))).shape) == [3,2,7,6]\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> type(BatchNorm2d(2)(torch.zeros((3,2,7,6)))) == torch.Tensor\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> hasattr(BatchNorm2d(2), 'gamma') and hasattr(BatchNorm2d(2), 'beta')\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> layer = BatchNorm2d(7)\n>>> (list(layer.gamma.shape) == [7])  and (list(layer.beta.shape) == [7])\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "Convolution Layer": {
          "name": "Convolution Layer",
          "points": 15,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> list(Conv2d(3,7,9)(torch.zeros((10, 3,64,64))).shape) == [10,7,56,56]\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> type(Conv2d(1,3,2)(torch.zeros((7,1,32,32)))) in [torch.Tensor, torch.nn.Parameter]\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> hasattr(Conv2d(1,1,1), 'w') and hasattr(Conv2d(1,1,1), 'b')\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> layer = Conv2d(7,32,4)\n>>> (list(layer.w.shape) == [32,7,4,4])  and (list(layer.b.shape) == [32])\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "Linear Layer": {
          "name": "Linear Layer",
          "points": 5,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> list(Linear(25,28)(torch.zeros((17,25))).shape) == [17,28]\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> type(Linear(13,15)(torch.zeros((6,13)))) in [torch.Tensor, torch.nn.Parameter]\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> hasattr(Linear(2,2), 'w') and hasattr(Linear(2,2), 'b')\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> layer = Linear(13,24)\n>>> (list(layer.w.shape) in [[13,24], [24,13]])  and (list(layer.b.shape) == [24])\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "MaxPool Layer": {
          "name": "MaxPool Layer",
          "points": 15,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> list(MaxPool2d(3)(torch.zeros((10,3,64,64))).shape) == [10,3,21,21]\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> type(MaxPool2d(3)(torch.zeros((10,3,64,64)))) in [torch.Tensor]\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}